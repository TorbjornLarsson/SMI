{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TorbjornLarsson/SMI/blob/main/mnist_fivelayers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "tags": [],
        "id": "u93S4zc79G-z"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# use GPU for computations if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# temporarily patch this script until the MNIST data set download issue is resolved\n",
        "# https://github.com/pytorch/vision/issues/1938\n",
        "import urllib.request\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "2ZfaQIUpDZvO",
        "tags": []
      },
      "source": [
        "# Classification of hand-written digits\n",
        "\n",
        "We start by downloading and extracting the MNIST data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "4BYGyJh69G-4"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transforms.ToTensor())\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                     download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# extract a complete PyTorch dataset\n",
        "def extract(dataset):\n",
        "    datasize = len(dataset)\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=datasize, shuffle=False)\n",
        "    return next(iter(dataloader))\n",
        "\n",
        "# extract all test images and labels into PyTorch tensors\n",
        "# the training data will be loaded in batches during training\n",
        "test_X, test_Y = extract(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JetLsyAjDZv3",
        "tags": []
      },
      "source": [
        "## The model\n",
        "\n",
        "The input data $X$ are grayscale images of $28\\times 28$ pixels. The first dimension will be the number of data points that are provided to the network. The input data is flattend into a matrix with $28 \\times 28 = 784$ columns using `X.view(-1, 784)`, where each colum represents one pixel. We then apply first the linear transformation $X W + b$ and then the softmax function to obtain the class probabilities predicted by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "tags": [],
        "id": "ump9fKVI9G-6"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # the weights of dimension (784, 10)\n",
        "        # self.W = nn.Parameter(torch.zeros(784, 10))\n",
        "        # the offset vector of dimension (10,)\n",
        "        # self.b = nn.Parameter(torch.zeros(10))\n",
        "        U1 = 200 # number of units in the first hidden layer\n",
        "        self.W1 = nn.Parameter(0.1 * torch.randn(784, U1))\n",
        "        self.b1 = nn.Parameter(torch.zeros(U1))\n",
        "        U2 = 100 # number of units in the second hidden layer\n",
        "        self.W2 = nn.Parameter(0.1 * torch.randn(U1, U2))\n",
        "        self.b2 = nn.Parameter(torch.zeros(U2))\n",
        "        U3 = 60 # number of units in the third hidden layer\n",
        "        self.W3 = nn.Parameter(0.1 * torch.randn(U2, U3))\n",
        "        self.b3 = nn.Parameter(torch.zeros(U3))\n",
        "        U4 = 30 # number of units in the third hidden layer\n",
        "        self.W4 = nn.Parameter(0.1 * torch.randn(U3, U4))\n",
        "        self.b4 = nn.Parameter(torch.zeros(U4))\n",
        "        self.W5 = nn.Parameter(0.1 * torch.randn(U4, 10))\n",
        "        #self.b5 = nn.Parameter(torch.zeros(10))\n",
        "        self.b5 = nn.Parameter(torch.ones(10)/10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # flatten the data into a matrix with 28 x 28 = 784 columns\n",
        "        X = X.view(-1, 784)\n",
        "        # compute the linear transformation\n",
        "        # Z = X.mm(self.W) + self.b\n",
        "        # apply the softmax function\n",
        "        # G = F.softmax(Z, dim=1)\n",
        "        Q1 = F.relu(X.mm(self.W1) + self.b1)\n",
        "        Q2 = F.relu(Q1.mm(self.W2) + self.b2)\n",
        "        Q3 = F.relu(Q2.mm(self.W3) + self.b3)\n",
        "        Q4 = F.relu(Q3.mm(self.W4) + self.b4)\n",
        "        #G = F.softmax(Q4.mm(self.W5) + self.b5, dim=1)\n",
        "        Z = Q4.mm(self.W5) + self.b5\n",
        "        return Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYMZmV_GDZwa",
        "tags": []
      },
      "source": [
        "## The training\n",
        "\n",
        "We define the cross-entropy for the predicted probabilities $G$ (10-dimensional vectors) and the labels $Y$ (integers between 0 and 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "cOpD7LKcDZwe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def crossentropy(G, Y):\n",
        "    # convert labels to onehot encoding\n",
        "    Y_onehot = torch.eye(10, device=device)[Y]\n",
        "\n",
        "    return -(Y_onehot * G.log()).sum(dim = 1).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSpeO0byDZwx",
        "tags": []
      },
      "source": [
        "The next lines evaluate the accuracy of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "G1B5xLOnDZw0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def accuracy(G, Y):\n",
        "    return (G.argmax(dim=1) == Y).float().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rJ4jX9FDDZxB",
        "tags": []
      },
      "source": [
        "We are ready to train the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyWis8FN9G-8",
        "outputId": "37246a95-7da1-4520-d55c-fb05fe6dbcbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step     0: train accuracy  14.00% train cross-entropy  2.30  test accuracy  11.89% test cross-entropy   nan\n",
            "Step   100: train accuracy  86.00% train cross-entropy  0.32  test accuracy  91.89% test cross-entropy   nan\n",
            "Step   200: train accuracy  93.00% train cross-entropy  0.20  test accuracy  93.28% test cross-entropy   nan\n",
            "Step   300: train accuracy  96.00% train cross-entropy  0.12  test accuracy  95.11% test cross-entropy   nan\n",
            "Step   400: train accuracy  97.00% train cross-entropy  0.09  test accuracy  95.85% test cross-entropy   nan\n",
            "Step   500: train accuracy  94.00% train cross-entropy  0.23  test accuracy  95.57% test cross-entropy   nan\n",
            "Step   600: train accuracy  96.00% train cross-entropy  0.10  test accuracy  96.70% test cross-entropy   nan\n",
            "Step   700: train accuracy  96.00% train cross-entropy  0.14  test accuracy  96.09% test cross-entropy   nan\n",
            "Step   800: train accuracy  99.00% train cross-entropy  0.06  test accuracy  96.49% test cross-entropy   nan\n",
            "Step   900: train accuracy  93.00% train cross-entropy  0.20  test accuracy  96.82% test cross-entropy   nan\n",
            "Step  1000: train accuracy  97.00% train cross-entropy  0.10  test accuracy  96.84% test cross-entropy   nan\n",
            "Step  1100: train accuracy  98.00% train cross-entropy  0.06  test accuracy  97.27% test cross-entropy   nan\n",
            "Step  1200: train accuracy  99.00% train cross-entropy  0.04  test accuracy  96.57% test cross-entropy   nan\n",
            "Step  1300: train accuracy  99.00% train cross-entropy  0.06  test accuracy  96.63% test cross-entropy   nan\n",
            "Step  1400: train accuracy  99.00% train cross-entropy  0.05  test accuracy  97.43% test cross-entropy   nan\n",
            "Step  1500: train accuracy  96.00% train cross-entropy  0.10  test accuracy  97.46% test cross-entropy   nan\n",
            "Step  1600: train accuracy  98.00% train cross-entropy  0.05  test accuracy  96.97% test cross-entropy   nan\n",
            "Step  1700: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.42% test cross-entropy   nan\n",
            "Step  1800: train accuracy  98.00% train cross-entropy  0.07  test accuracy  95.88% test cross-entropy   nan\n",
            "Step  1900: train accuracy  98.00% train cross-entropy  0.07  test accuracy  97.15% test cross-entropy   nan\n",
            "Step  2000: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.45% test cross-entropy   nan\n",
            "Step  2100: train accuracy  96.00% train cross-entropy  0.08  test accuracy  97.33% test cross-entropy   nan\n",
            "Step  2200: train accuracy  95.00% train cross-entropy  0.12  test accuracy  97.33% test cross-entropy   nan\n",
            "Step  2300: train accuracy  98.00% train cross-entropy  0.04  test accuracy  97.80% test cross-entropy   nan\n",
            "Step  2400: train accuracy  98.00% train cross-entropy  0.07  test accuracy  97.34% test cross-entropy   nan\n",
            "Step  2500: train accuracy  99.00% train cross-entropy  0.03  test accuracy  97.50% test cross-entropy   nan\n",
            "Step  2600: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.37% test cross-entropy   nan\n",
            "Step  2700: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.57% test cross-entropy   nan\n",
            "Step  2800: train accuracy  96.00% train cross-entropy  0.15  test accuracy  97.53% test cross-entropy   nan\n",
            "Step  2900: train accuracy  99.00% train cross-entropy  0.05  test accuracy  97.50% test cross-entropy   nan\n",
            "Step  3000: train accuracy  99.00% train cross-entropy  0.01  test accuracy  97.59% test cross-entropy   nan\n",
            "Step  3100: train accuracy  97.00% train cross-entropy  0.06  test accuracy  97.31% test cross-entropy   nan\n",
            "Step  3200: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.81% test cross-entropy   nan\n",
            "Step  3300: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.84% test cross-entropy   nan\n",
            "Step  3400: train accuracy  99.00% train cross-entropy  0.04  test accuracy  98.01% test cross-entropy   nan\n",
            "Step  3500: train accuracy  96.00% train cross-entropy  0.15  test accuracy  96.98% test cross-entropy   nan\n",
            "Step  3600: train accuracy  99.00% train cross-entropy  0.03  test accuracy  97.52% test cross-entropy   nan\n",
            "Step  3700: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.83% test cross-entropy   nan\n",
            "Step  3800: train accuracy  98.00% train cross-entropy  0.04  test accuracy  97.40% test cross-entropy   nan\n",
            "Step  3900: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.42% test cross-entropy   nan\n",
            "Step  4000: train accuracy  97.00% train cross-entropy  0.09  test accuracy  98.03% test cross-entropy   nan\n",
            "Step  4100: train accuracy  99.00% train cross-entropy  0.06  test accuracy  97.75% test cross-entropy   nan\n",
            "Step  4200: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.61% test cross-entropy   nan\n",
            "Step  4300: train accuracy  99.00% train cross-entropy  0.08  test accuracy  97.74% test cross-entropy   nan\n",
            "Step  4400: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.10% test cross-entropy   nan\n",
            "Step  4500: train accuracy  99.00% train cross-entropy  0.04  test accuracy  97.65% test cross-entropy   nan\n",
            "Step  4600: train accuracy  99.00% train cross-entropy  0.10  test accuracy  97.37% test cross-entropy   nan\n",
            "Step  4700: train accuracy  98.00% train cross-entropy  0.05  test accuracy  97.77% test cross-entropy   nan\n",
            "Step  4800: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.61% test cross-entropy   nan\n",
            "Step  4900: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.59% test cross-entropy   nan\n",
            "Step  5000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.03% test cross-entropy   nan\n",
            "Step  5100: train accuracy  96.00% train cross-entropy  0.10  test accuracy  97.63% test cross-entropy   nan\n",
            "Step  5200: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.67% test cross-entropy   nan\n",
            "Step  5300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.90% test cross-entropy   nan\n",
            "Step  5400: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.90% test cross-entropy   nan\n",
            "Step  5500: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.88% test cross-entropy   nan\n",
            "Step  5600: train accuracy  99.00% train cross-entropy  0.11  test accuracy  97.68% test cross-entropy   nan\n",
            "Step  5700: train accuracy  98.00% train cross-entropy  0.08  test accuracy  97.78% test cross-entropy   nan\n",
            "Step  5800: train accuracy  99.00% train cross-entropy  0.06  test accuracy  97.78% test cross-entropy   nan\n",
            "Step  5900: train accuracy  98.00% train cross-entropy  0.12  test accuracy  97.82% test cross-entropy   nan\n",
            "Step  6000: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.46% test cross-entropy   nan\n",
            "Step  6100: train accuracy  98.00% train cross-entropy  0.04  test accuracy  97.81% test cross-entropy   nan\n",
            "Step  6200: train accuracy  97.00% train cross-entropy  0.06  test accuracy  97.46% test cross-entropy   nan\n",
            "Step  6300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.63% test cross-entropy   nan\n",
            "Step  6400: train accuracy  98.00% train cross-entropy  0.05  test accuracy  97.93% test cross-entropy   nan\n",
            "Step  6500: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.92% test cross-entropy   nan\n",
            "Step  6600: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.13% test cross-entropy   nan\n",
            "Step  6700: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.48% test cross-entropy   nan\n",
            "Step  6800: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.00% test cross-entropy   nan\n",
            "Step  6900: train accuracy  98.00% train cross-entropy  0.02  test accuracy  97.80% test cross-entropy   nan\n",
            "Step  7000: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.90% test cross-entropy   nan\n",
            "Step  7100: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.61% test cross-entropy   nan\n",
            "Step  7200: train accuracy  98.00% train cross-entropy  0.04  test accuracy  97.94% test cross-entropy   nan\n",
            "Step  7300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.20% test cross-entropy   nan\n",
            "Step  7400: train accuracy  99.00% train cross-entropy  0.05  test accuracy  98.08% test cross-entropy   nan\n",
            "Step  7500: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.87% test cross-entropy   nan\n",
            "Step  7600: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.93% test cross-entropy   nan\n",
            "Step  7700: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.89% test cross-entropy   nan\n",
            "Step  7800: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.69% test cross-entropy   nan\n",
            "Step  7900: train accuracy  98.00% train cross-entropy  0.04  test accuracy  98.02% test cross-entropy   nan\n",
            "Step  8000: train accuracy  99.00% train cross-entropy  0.01  test accuracy  97.97% test cross-entropy   nan\n",
            "Step  8100: train accuracy 100.00% train cross-entropy  0.01  test accuracy  97.96% test cross-entropy   nan\n",
            "Step  8200: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.92% test cross-entropy   nan\n",
            "Step  8300: train accuracy  99.00% train cross-entropy  0.03  test accuracy  97.80% test cross-entropy   nan\n",
            "Step  8400: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.09% test cross-entropy   nan\n",
            "Step  8500: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.03% test cross-entropy   nan\n",
            "Step  8600: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.56% test cross-entropy   nan\n",
            "Step  8700: train accuracy 100.00% train cross-entropy  0.02  test accuracy  97.88% test cross-entropy   nan\n",
            "Step  8800: train accuracy  99.00% train cross-entropy  0.01  test accuracy  97.84% test cross-entropy   nan\n",
            "Step  8900: train accuracy  99.00% train cross-entropy  0.03  test accuracy  97.27% test cross-entropy   nan\n",
            "Step  9000: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.29% test cross-entropy   nan\n",
            "Step  9100: train accuracy  97.00% train cross-entropy  0.09  test accuracy  98.07% test cross-entropy   nan\n",
            "Step  9200: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.91% test cross-entropy   nan\n",
            "Step  9300: train accuracy 100.00% train cross-entropy  0.00  test accuracy  97.96% test cross-entropy   nan\n",
            "Step  9400: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.31% test cross-entropy   nan\n",
            "Step  9500: train accuracy 100.00% train cross-entropy  0.01  test accuracy  98.23% test cross-entropy   nan\n",
            "Step  9600: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.11% test cross-entropy   nan\n",
            "Step  9700: train accuracy  99.00% train cross-entropy  0.01  test accuracy  98.04% test cross-entropy   nan\n",
            "Step  9800: train accuracy 100.00% train cross-entropy  0.00  test accuracy  98.12% test cross-entropy   nan\n",
            "Step  9900: train accuracy  99.00% train cross-entropy  0.01  test accuracy  97.75% test cross-entropy   nan\n",
            "Step 10000: train accuracy  99.00% train cross-entropy  0.02  test accuracy  97.88% test cross-entropy   nan\n"
          ]
        }
      ],
      "source": [
        "# initialize the test and training error statistics\n",
        "test_accuracy = []\n",
        "test_crossentropy = []\n",
        "test_iter = []\n",
        "train_accuracy = []\n",
        "train_crossentropy = []\n",
        "train_iter = []\n",
        "\n",
        "# initialize the neural network and move it to the GPU if needed\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "# define the optimization algorithm\n",
        "learningrate = 0.003\n",
        "optimizer = optim.Adam(net.parameters(), lr=learningrate)\n",
        "\n",
        "# define the data loader for batches of the training data\n",
        "batchsize = 100\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, num_workers=2, shuffle=True)\n",
        "\n",
        "# perform multiple training steps\n",
        "total_iterations = 10000 # total number of iterations\n",
        "t = 0 # current iteration\n",
        "done = False\n",
        "while not done:\n",
        "    for (batch_X, batch_Y) in trainloader:\n",
        "        # move batch to the GPU if needed\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        batch_G = net(batch_X)\n",
        "        loss = F.cross_entropy(batch_G, batch_Y)\n",
        "\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # perform gradient descent step\n",
        "        optimizer.step()\n",
        "\n",
        "        # don't bother too much about the following lines!\n",
        "        with torch.no_grad():\n",
        "            # evaluate the performance on the training data at every 10th iteration\n",
        "            if t % 10 == 0:\n",
        "                train_crossentropy.append(loss.item())\n",
        "                train_accuracy.append(accuracy(batch_G, batch_Y).item())\n",
        "                train_iter.append(t)\n",
        "\n",
        "            # evaluate the performance on the test data at every 100th iteration\n",
        "            if t % 100 == 0:\n",
        "                # move test data to the GPU if needed\n",
        "                X, Y = test_X.to(device), test_Y.to(device)\n",
        "\n",
        "                # compute predictions for the test data\n",
        "                G = net(X)\n",
        "                test_crossentropy.append(crossentropy(G, Y).item())\n",
        "                test_accuracy.append(accuracy(G, Y).item())\n",
        "                test_iter.append(t)\n",
        "\n",
        "                # print the iteration number and the accuracy of the predictions\n",
        "                print(f\"Step {t:5d}: train accuracy {100 * train_accuracy[-1]:6.2f}% \" \\\n",
        "                      f\"train cross-entropy {train_crossentropy[-1]:5.2f}  \" \\\n",
        "                      f\"test accuracy {100 * test_accuracy[-1]:6.2f}% \" \\\n",
        "                      f\"test cross-entropy {test_crossentropy[-1]:5.2f}\")\n",
        "\n",
        "        # stop the training after the specified number of iterations\n",
        "        t += 1\n",
        "        if t > total_iterations:\n",
        "            done = True\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY9MEi2xDZxM",
        "tags": []
      },
      "source": [
        "## The evaluation\n",
        "\n",
        "The remaining code produces the plots needed to evaluate the training and predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "L_MSLJvoD28u",
        "outputId": "d48120da-d1a3-4814-fc39-1dc137f4a26e",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Axis limits cannot be NaN or Inf",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1008110143.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross-entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_crossentropy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross-entropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mylim\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2158\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mset_ylim\u001b[0;34m(self, bottom, top, emit, auto, ymin, ymax)\u001b[0m\n\u001b[1;32m   4015\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot pass both 'top' and 'ymax'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4016\u001b[0m             \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4017\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_lim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4019\u001b[0m     \u001b[0mget_yscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_axis_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yaxis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_scale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_lim\u001b[0;34m(self, v0, v1, emit, auto)\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_unit_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_converted_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1228\u001b[0;31m         \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_converted_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mv0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_validate_converted_limits\u001b[0;34m(self, limit, convert)\u001b[0m\n\u001b[1;32m   3702\u001b[0m             if (isinstance(converted_limit, Real)\n\u001b[1;32m   3703\u001b[0m                     and not np.isfinite(converted_limit)):\n\u001b[0;32m-> 3704\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Axis limits cannot be NaN or Inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3705\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Axis limits cannot be NaN or Inf"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot the cross-entropy\n",
        "plt.plot(train_iter, train_crossentropy, 'b-', label='Training data (mini-batch)')\n",
        "plt.plot(test_iter, test_crossentropy, 'r-', label='Test data')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cross-entropy')\n",
        "plt.ylim([0, min(test_crossentropy) * 3])\n",
        "plt.title('Cross-entropy')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(train_iter, train_accuracy, 'b-', label='Training data (mini-batch)')\n",
        "plt.plot(test_iter, test_accuracy, 'r-', label='Test data')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Prediction accuracy')\n",
        "plt.ylim([max(1 - (1 - test_accuracy[-1]) * 2, 0), 1])\n",
        "plt.title('Prediction accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caWJ8PwaDZxO",
        "scrolled": false,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# evaluate the network on 100 random test images\n",
        "with torch.no_grad():\n",
        "    # obtain 100 random samples from the test data set\n",
        "    random_X, random_Y = next(iter(torch.utils.data.DataLoader(testset, batch_size=100, shuffle=True)))\n",
        "\n",
        "    # move data to the GPU if needed\n",
        "    random_X, random_Y = random_X.to(device), random_Y.to(device)\n",
        "\n",
        "    # compute the predictions for the sampled inputs\n",
        "    random_G = net(random_X)\n",
        "    random_Yhat = random_G.argmax(dim=1)\n",
        "\n",
        "    # sort the predictions with the incorrect ones first\n",
        "    indices_incorrect_first = (random_Yhat == random_Y).float().argsort()\n",
        "\n",
        "# plot the images\n",
        "num_rows = 10\n",
        "num_cols = 10\n",
        "num_images = num_rows * num_cols\n",
        "plt.figure(figsize=(num_cols, num_rows))\n",
        "\n",
        "for i, index in enumerate(indices_incorrect_first, 1):\n",
        "    plt.subplot(num_rows, num_cols, i)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    # plot the image\n",
        "    plt.imshow(random_X[index, :, :].view(28, 28).cpu().numpy(), cmap=plt.cm.binary)\n",
        "\n",
        "    # add the prediction as annotation (incorrect predictions in red, correct ones in blue)\n",
        "    color = 'blue' if random_Yhat[index] == random_Y[index] else 'red'\n",
        "    plt.text(0, 25, random_Yhat[index].item(), fontsize=25, color=color)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "anaconda-cloud": {},
    "celltoolbar": "Tags",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "lab-sml",
      "language": "python",
      "name": "lab-sml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}